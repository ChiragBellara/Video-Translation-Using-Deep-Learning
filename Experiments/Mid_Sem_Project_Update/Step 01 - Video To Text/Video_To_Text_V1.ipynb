{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#### Links to Models\n",
        "##### OpenAI Whisper: https://github.com/openai/whisper\n",
        "##### Google SR: https://github.com/Uberi/speech_recognition#readme\n",
        "###### By default, the SpeechRecognition Library uses the Google SR unless it is asked to use any other recognizer.\n",
        "##### Facebook Wav2Vec: https://github.com/facebookresearch/fairseq/blob/main/examples/wav2vec/README.md"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9c6UlLCmpjKe"
      },
      "outputs": [],
      "source": [
        "## Declaring some constants\n",
        "OUTPUT_VIDEO = \"/content/Drive/MyDrive/DownloadedVideos/downloadedVideo.mkv\"\n",
        "OUTPUT_AUDIO = \"/content/Drive/MyDrive/OutcomeAudios/extractedAudio.wav\"\n",
        "AUDIO_FOLDER = \"/content/Drive/MyDrive/OutcomeAudios/\"\n",
        "VIDEO_FOLDER = \"/content/Drive/MyDrive/DownloadedVideos/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nHcZvMkkQd17",
        "outputId": "12d9f200-91d7-4e0d-ca89-ada82e408b40"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Reading package lists...\n",
            "Building dependency tree...\n",
            "Reading state information...\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 18 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "## Instaling dependencies for downloading the video and extracting the audio\n",
        "!apt install ffmpeg -q\n",
        "!pip install yt_dlp -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "ytH7qJ-UNLQf"
      },
      "outputs": [],
      "source": [
        "import time"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FsrrK57lVR7o",
        "outputId": "cf8067b8-4661-420c-b903-918cde674d0c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/Drive; to attempt to forcibly remount, call drive.mount(\"/content/Drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "rbEaJ2wCV6ir"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "def checkAndMakeDir(folder):\n",
        "  if os.path.exists(folder)==False:\n",
        "    os.makedirs(folder)\n",
        "\n",
        "checkAndMakeDir(AUDIO_FOLDER)\n",
        "checkAndMakeDir(VIDEO_FOLDER)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "JkyW8XBtYb9M"
      },
      "outputs": [],
      "source": [
        "## Here we are downloading the video from the Youtube URL\n",
        "## storing it in DownloadedVideos folder.\n",
        "## We have given that the format of download should be mp4\n",
        "## so that the video that gets downloaded is stored as an\n",
        "## mkv file to make it easier to begin processing.\n",
        "from yt_dlp import YoutubeDL\n",
        "\n",
        "## Parameters: URL to the Youtube Video as a String\n",
        "def downloadVideoYT(URL):\n",
        "  ytdl_format_options = {\n",
        "    'outtmpl': OUTPUT_VIDEO,\n",
        "    'format': 'best[ext=mp4]'\n",
        "  }\n",
        "  with YoutubeDL(ytdl_format_options) as ydl:\n",
        "    ydl.download([URL])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bmXo1i85VlU8",
        "outputId": "5fae2304-c7d0-4c88-9869-3a7c084686d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[youtube] Extracting URL: https://www.youtube.com/watch?v=n8zSEZX8S5w&ab_channel=FelL.\n",
            "[youtube] n8zSEZX8S5w: Downloading webpage\n",
            "[youtube] n8zSEZX8S5w: Downloading ios player API JSON\n",
            "[youtube] n8zSEZX8S5w: Downloading android player API JSON\n",
            "[youtube] n8zSEZX8S5w: Downloading m3u8 information\n",
            "[info] n8zSEZX8S5w: Downloading 1 format(s): 22\n",
            "[download] Destination: /content/Drive/MyDrive/DownloadedVideos/downloadedVideo.mkv\n",
            "[download] 100% of    8.91MiB in 00:00:01 at 7.36MiB/s   \n",
            "Download Completed\n",
            "Time to Download : 2.323329448699951 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "videoURL = \"https://www.youtube.com/watch?v=n8zSEZX8S5w&ab_channel=FelL.\"\n",
        "downloadVideoYT(videoURL)\n",
        "print(\"Download Completed\")\n",
        "print(\"Time to Download : %s seconds\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a2H6gmkRg3Rc",
        "outputId": "4885d4ee-cf71-4902-a0f0-4e071e3210ce"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Time to Extract Audio : 0.4411797523498535 seconds\n"
          ]
        }
      ],
      "source": [
        "## We use ffpmeg to extract the audio from the video,\n",
        "## by giving the input video location as the parameter for -i (input).\n",
        "## The -y (global) is used to Overwrite output files without asking.\n",
        "\n",
        "import subprocess\n",
        "\n",
        "def extractAudio():\n",
        "  subprocess.call([\"ffmpeg\",\n",
        "                   \"-y\",\n",
        "                   \"-i\",\n",
        "                   OUTPUT_VIDEO,\n",
        "                   OUTPUT_AUDIO])\n",
        "                  #stdout=subprocess.DEVNULL,\n",
        "                  #stderr=subprocess.STDOUT\n",
        "\n",
        "start_time = time.time()\n",
        "extractAudio()\n",
        "print(\"Time to Extract Audio : %s seconds\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "emlCrx7QMMlQ"
      },
      "source": [
        "### Converting the Speech to Text using OpenAI Whisper"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "D-HCHVKfekck",
        "outputId": "2e96416e-e420-4ae3-cc91-e9c3f90d3d27"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n"
          ]
        }
      ],
      "source": [
        "!pip install tiktoken -q\n",
        "!pip install cohere -q\n",
        "!pip install openai -q\n",
        "!pip install git+https://github.com/openai/whisper.git -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "5CvmAgS6nurl"
      },
      "outputs": [],
      "source": [
        "import whisper\n",
        "transcriptModel = whisper.load_model('base')\n",
        "\n",
        "## I am using the BASE model for now, to ensure higher accuracy and better results, we can even use a bigger whisper model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UmOqt9N3o8u9",
        "outputId": "f9b21849-91f6-40a0-a869-f509d397e4cf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "OpenAI Whisper : 9.558514833450317 seconds\n",
            " Hello there! My name is Phil. I have been an online English tutor for almost three years now. I've been helping students from beginner to advanced level improve their English skills. I've tried teaching kids and adults. I used CPR. Look! Rewards! And many more! I would love to help you improve and make progress in learning. From phonics, grammar, pronunciation and up to conversational English. I've already earned my Tassel and Tia Felt certificate, so you're in good hands. Learn with me and let's make English a fun and easy language. See ya!\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "## Parameters: Path to the audio file as a String\n",
        "result = transcriptModel.transcribe(OUTPUT_AUDIO)\n",
        "print(\"OpenAI Whisper : %s seconds\" % (time.time() - start_time))\n",
        "print(result['text'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYyo-d4AMVkS"
      },
      "source": [
        "### Converting the Speech to Text using Google Recognition"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "J86J4ikfpQVn"
      },
      "outputs": [],
      "source": [
        "!pip install pytube -q\n",
        "!pip install moviepy -q\n",
        "!pip install SpeechRecognition -q\n",
        "!pip install pydub -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CsoIENr3xAl8",
        "outputId": "0d8da206-8468-4b7a-cc06-dfa9712cb687"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Google SR : 12.385565996170044 seconds\n"
          ]
        }
      ],
      "source": [
        "import speech_recognition as sr\n",
        "import os\n",
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence\n",
        "\n",
        "r = sr.Recognizer()\n",
        "\n",
        "## Parameters: Path to the audio file as a String\n",
        "def transcribe_audio(path):\n",
        "    with sr.AudioFile(path) as source:\n",
        "        audio_listened = r.record(source)\n",
        "        text = r.recognize_google(audio_listened)\n",
        "    return text\n",
        "\n",
        "start_time = time.time()\n",
        "transcribe_audio(OUTPUT_AUDIO)\n",
        "print(\"Google SR : %s seconds\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WPG4ul-MMdII"
      },
      "source": [
        "### Converting the Speech to Text using Facebook's Wav2Vec Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "31e5jeZVw1_Y"
      },
      "outputs": [],
      "source": [
        "from scipy.io import wavfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLW-cPulyIce",
        "outputId": "628cf402-71ae-4cbe-c1a9-5d95dc75d3c6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Frame Rate: 44100\n",
            "Total Time: 48.204625850340136\n"
          ]
        }
      ],
      "source": [
        "## Parameters: Path to the audio file as a String\n",
        "data = wavfile.read(OUTPUT_AUDIO)\n",
        "print(\"Frame Rate: \" + str(data[0]))\n",
        "print(\"Total Time: \" + str(len(data[1]) / data[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "iOsWfxe0yce-"
      },
      "outputs": [],
      "source": [
        "!pip install transformers -q"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "6dKBwGE8y7GB"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "import torch\n",
        "import librosa\n",
        "from transformers import Wav2Vec2ForCTC, Wav2Vec2Tokenizer"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A4q-Sa6VzXtl",
        "outputId": "79b5aba8-085f-45cc-e923-089e4f0331c8"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "The tokenizer class you load from this checkpoint is not the same type as the class this function is called from. It may result in unexpected tokenization. \n",
            "The tokenizer class you load from this checkpoint is 'Wav2Vec2CTCTokenizer'. \n",
            "The class this function is called from is 'Wav2Vec2Tokenizer'.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/models/wav2vec2/tokenization_wav2vec2.py:736: FutureWarning: The class `Wav2Vec2Tokenizer` is deprecated and will be removed in version 5 of Transformers. Please use `Wav2Vec2Processor` or `Wav2Vec2CTCTokenizer` instead.\n",
            "  warnings.warn(\n",
            "Some weights of Wav2Vec2ForCTC were not initialized from the model checkpoint at facebook/wav2vec2-base-960h and are newly initialized: ['wav2vec2.masked_spec_embed']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ],
      "source": [
        "tokenizer = Wav2Vec2Tokenizer.from_pretrained(\"facebook/wav2vec2-base-960h\")\n",
        "fbModel = Wav2Vec2ForCTC.from_pretrained(\"facebook/wav2vec2-base-960h\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SUYEmEaFzw-6",
        "outputId": "32234afa-7f4b-4964-d1e1-99b96ec9ae10"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Facebook Wav2Vec : 50.68428087234497 seconds\n"
          ]
        }
      ],
      "source": [
        "start_time = time.time()\n",
        "inputAudio,_ = librosa.load(OUTPUT_AUDIO, sr=16000)\n",
        "inputValues = tokenizer(inputAudio, return_tensors = \"pt\").input_values\n",
        "logits = fbModel(inputValues).logits\n",
        "predictedIDs = torch.argmax(logits, dim = -1)\n",
        "outcomeText = tokenizer.batch_decode(predictedIDs)[0]\n",
        "print(\"Facebook Wav2Vec : %s seconds\" % (time.time() - start_time))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "id": "gOXwLhgQ0oa3",
        "outputId": "fdb7e368-eae2-4e7c-a32b-22c0ead39af4"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"NOW LO THERE MY NAM IS FELL I HAVE BEEN AN ANLIN ENGLISH TUTOR FOR ALMOST THREE YEARS NOW I'VE BEEN HELPING STUDENTS FROM BIGINNER TO ADVANCE LEVELL IMPROVE THEIR ENGLISH SKILLS I'VE TRIED TEA CHING KITS AND ADALS I USED TE PY ARE LOOK REWARDS AND MANY MARE I WOULD LOVE TO HELP YOU IMPROVE AND MAKE PROGRESS IN LEARNING FROM FENIX GRAMMAR PRONUNCATION AND OUPHT TO CONVERSATIONAL ENGLISH I'VE ALREADY EARNED MY TUSSLE AND TEA FELT CERTIFICATE SO YOU ARE IN GOOD HANDS LEARN WITH ME AND LET'S MAKE ENGLISH A FUN AND EASY LANGUAGE SEE A\""
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "outcomeText"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Eopu3mJ5O7a5"
      },
      "source": [
        "### Time of execution of different steps and models\n",
        "#### Video Length: 48sec\n",
        "\n",
        "| Step    | Time of Execution (in sec)|\n",
        "| :---        |    :----:   |\n",
        "| Downloaing the video      | 2.32       |\n",
        "| Extracting the audio   | 0.44        |\n",
        "| OpenAI Whisper   | 9.56        |\n",
        "| Google SR   | 12.39        |\n",
        "| Wav2Vec   | 50.68        |"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
