{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Transcribe and Translation using OpenAI Whisper\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "JS8Wa_b8Sa1V"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI's Whisper is a general-purpose speech recognition model that you can use to transcribe or translate audio files."
      ],
      "metadata": {
        "id": "remrrjDCSOUs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Links to Models\n",
        "##### Whisper: https://github.com/openai/whisper"
      ],
      "metadata": {
        "id": "pClwguIGSqNn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import time"
      ],
      "metadata": {
        "id": "GRQBbkOwx4ga"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/Drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WCkahfqOyVwa",
        "outputId": "791ce2ba-56a6-42a1-9888-b8858e77c636"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/Drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CYXelRt8OPTh",
        "outputId": "ab6d8bde-814f-450a-ef37-fcad091ffab3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting git+https://github.com/openai/whisper.git\n",
            "  Cloning https://github.com/openai/whisper.git to /tmp/pip-req-build-aem5yzv7\n",
            "  Running command git clone --filter=blob:none --quiet https://github.com/openai/whisper.git /tmp/pip-req-build-aem5yzv7\n",
            "  Resolved https://github.com/openai/whisper.git to commit 1cea4357687b676b293cb5473e1ade25f5b1cef7\n",
            "  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: triton<3,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0)\n",
            "Requirement already satisfied: numba in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (0.58.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (1.23.5)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (2.1.0+cu118)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (4.66.1)\n",
            "Requirement already satisfied: more-itertools in /usr/local/lib/python3.10/dist-packages (from openai-whisper==20231106) (10.1.0)\n",
            "Collecting tiktoken (from openai-whisper==20231106)\n",
            "  Downloading tiktoken-0.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.0 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.0/2.0 MB\u001b[0m \u001b[31m20.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from triton<3,>=2.0.0->openai-whisper==20231106) (3.13.1)\n",
            "Requirement already satisfied: llvmlite<0.42,>=0.41.0dev0 in /usr/local/lib/python3.10/dist-packages (from numba->openai-whisper==20231106) (0.41.1)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2023.6.3)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken->openai-whisper==20231106) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->openai-whisper==20231106) (2023.6.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken->openai-whisper==20231106) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->openai-whisper==20231106) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->openai-whisper==20231106) (1.3.0)\n",
            "Building wheels for collected packages: openai-whisper\n",
            "  Building wheel for openai-whisper (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openai-whisper: filename=openai_whisper-20231106-py3-none-any.whl size=801359 sha256=27006fa8bbefa938ca010ca664ac3535ec14c15be0c24e43a58c4502e3cdc916\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-t5_krphp/wheels/8b/6c/d0/622666868c179f156cf595c8b6f06f88bc5d80c4b31dccaa03\n",
            "Successfully built openai-whisper\n",
            "Installing collected packages: tiktoken, openai-whisper\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "llmx 0.0.15a0 requires cohere, which is not installed.\n",
            "llmx 0.0.15a0 requires openai, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed openai-whisper-20231106 tiktoken-0.5.1\n"
          ]
        }
      ],
      "source": [
        "# Install Whisper library from GitHub using pip.\n",
        "!pip install git+https://github.com/openai/whisper.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Update package information and install FFmpeg using apt.\n",
        "!sudo apt update && sudo apt install ffmpeg"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sO63pIPWOYDz",
        "outputId": "adaed965-76d8-41d2-86c7-fa413d3239ce"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [110 kB]\n",
            "\u001b[33m\r0% [Waiting for headers] [1 InRelease 5,482 B/110 kB 5%] [Connected to cloud.r-\u001b[0m\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "Get:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [119 kB]\n",
            "Get:5 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,626 B]\n",
            "Hit:6 http://archive.ubuntu.com/ubuntu jammy-backports InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [624 kB]\n",
            "Hit:8 https://ppa.launchpadcontent.net/c2d4u.team/c2d4u4.0+/ubuntu jammy InRelease\n",
            "Get:9 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [1,404 kB]\n",
            "Hit:10 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:11 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,277 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [1,203 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu jammy-security/universe amd64 Packages [1,010 kB]\n",
            "Hit:15 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [1,430 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [1,472 kB]\n",
            "Fetched 8,654 kB in 1s (6,018 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "14 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "ffmpeg is already the newest version (7:4.4.2-0ubuntu0.22.04.1).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Use Whisper to generate a transcript from the audio file \"audio.mp3\" using the \"medium\" model.\n",
        "start_time = time.time()\n",
        "\n",
        "!whisper \"tips.mp3\" --model medium\n",
        "\n",
        "print(\"Transcribed in : %s seconds\" % (time.time() - start_time))"
      ],
      "metadata": {
        "id": "yxrg4HS9OgEj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9e576c0-8a59-4530-8ab7-57e94091bd7f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Hindi\n",
            "[00:00.000 --> 00:02.980]  मुझे नहीं पता, कईबार इंटरविज में हमसे कोई सवाल पूछ लए जाथा हैं\n",
            "[00:02.980 --> 00:09.480]  जिसका आनसर हमें नहीं पदा होथा तो एसे में हमें ब्लांक फेस मणाकोड चुख भी नहीं बेतना होता और इंतर्वियर को लगता होता हैं\n",
            "[00:09.480 --> 00:11.480]  क्योंकि उससे उन्हें लग सकता है कि हम अपने टाइम वेस्त करें।\n",
            "[00:11.480 --> 00:14.480]  ऐसी सिटॉएशण में हमें अमेशा अणिस्ट और खुणफिदेंट रेना हैं।\n",
            "[00:14.480 --> 00:17.480]  अगर ऐसा सवाल हम से पूछ रहा जाता हैं जिसका अंसर हमें बिल्कुल भी नहीं आधा रहा।\n",
            "[00:17.480 --> 00:19.480]  तो उसके दो केसिस हो सकते हैं।\n",
            "[00:19.480 --> 00:22.480]  सबसे पेला केस यह हो सकता है कि उस टॉपिक को हमने आज तक पढ़ाई नहीं हैं।\n",
            "[00:22.480 --> 00:24.480]  तो ऐसे में हम कुछ इस तरीके का आंसर पर सकते हैं।\n",
            "[00:24.480 --> 00:26.480]  सॉरी माम बर इस टॉपिक के पर नहीं आदा रहा हैं।\n",
            "[00:27.480 --> 00:31.480]  इसे इंटेवियोर को पता चलेगा कि हम उस चीस के बारे में बतारे हैं।\n",
            "[00:31.480 --> 00:34.480]  प्लास हम इगर तू लरन है और नहीं चीजे सीखना शारे हैं।\n",
            "[00:35.480 --> 00:41.980]  इसके अधा\n",
            "[00:42.640 --> 00:45.480]  वालिको साथ vivir करता हैं।\n",
            "[00:45.480 --> 00:52.480]  इस तरीके से इंफ्रेत आल Aim इस बचाएजार है।\n",
            "[00:52.480 --> 00:56.480]  कि एलावा को इos के बार पर शक्छी क Antonio की सावरा करें।\n",
            "[00:56.480 --> 00:58.480]  मु actionable किनर बर।\n",
            "Transcribed in : 197.04172253608704 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start_time = time.time()\n",
        "\n",
        "# Use Whisper to translate speech from the audio file.\n",
        "!whisper \"tips.mp3\" --task translate\n",
        "\n",
        "print(\"Translation Time: %s seconds\" % (time.time() - start_time))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oY1xe5LNPB1z",
        "outputId": "1c886b59-be58-48f2-83a0-f09945e1855a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Detecting language using up to the first 30 seconds. Use `--language` to specify the language\n",
            "Detected language: Hindi\n",
            "[00:00.000 --> 00:01.000]  I don't know.\n",
            "[00:01.000 --> 00:03.000]  Many times we get asked questions in interviews\n",
            "[00:03.000 --> 00:04.500]  which we don't know the answer to.\n",
            "[00:04.500 --> 00:07.000]  In such a situation, we don't have to sit in a blank face\n",
            "[00:07.000 --> 00:09.000]  and we don't have to give an interviewer a fake answer\n",
            "[00:09.000 --> 00:12.000]  because they might think that we are wasting their time.\n",
            "[00:12.000 --> 00:14.500]  In such a situation, we always have to be honest and confident.\n",
            "[00:14.500 --> 00:16.000]  If we get asked such questions\n",
            "[00:16.000 --> 00:18.000]  which we don't remember the answer to at all,\n",
            "[00:18.000 --> 00:19.500]  then these can be two cases.\n",
            "[00:19.500 --> 00:22.000]  The first case is that we haven't studied that topic\n",
            "[00:22.000 --> 00:25.000]  so in such a situation, we can form an answer to this type of question.\n",
            "[00:25.000 --> 00:27.000]  Sorry ma'am, but I have not studied this topic yet.\n",
            "[00:27.000 --> 00:29.000]  Can I please request you to tell me more about this topic?\n",
            "[00:29.000 --> 00:32.000]  This interviewer will get to know that we are honestly telling you about it\n",
            "[00:32.000 --> 00:35.000]  plus we are eager to learn and want to learn new things.\n",
            "[00:35.000 --> 00:38.000]  Other than this, the second case can be that we have studied about this topic\n",
            "[00:38.000 --> 00:39.500]  but we still don't remember about it.\n",
            "[00:39.500 --> 00:41.500]  So we can give an answer to this type of question.\n",
            "[00:41.500 --> 00:43.500]  To be honest, I can't recall the answer right now\n",
            "[00:43.500 --> 00:45.500]  but I will definitely brush up more on it after the interview.\n",
            "[00:45.500 --> 00:48.500]  We have honestly told them that we still don't remember\n",
            "[00:48.500 --> 00:50.500]  plus we have also told them that after the interview\n",
            "[00:50.500 --> 00:52.500]  we will be reading more about that topic.\n",
            "[00:52.500 --> 00:54.500]  Other than this, there is another interview question\n",
            "[00:54.500 --> 00:55.500]  in which you get an issue.\n",
            "[00:55.500 --> 00:57.000]  You can comment below and let us know.\n",
            "[00:57.000 --> 00:59.000]  Till then, keep learning and keep exploring.\n",
            "Translation Time: 24.829750537872314 seconds\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time of execution using Whisper\n",
        "\n",
        "| Step    | Time of Execution (in sec)|\n",
        "| :---        |    :----:   |\n",
        "| Transcription    | 197      |\n",
        "| Translation  | 24.9      |"
      ],
      "metadata": {
        "id": "j7sMLePXf4I-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Time Taken to Translate by Different models\n",
        "\n",
        "| Model    | Time of Execution (in sec)|\n",
        "| :---        |    :----:   \n",
        "| Google Translate   | 0.21    |\n",
        "| Azure AI Translator | 0.55     |\n",
        "| MyMemory  | 0.14        |\n",
        "| OpenAI Whisper  | 24.9        |"
      ],
      "metadata": {
        "id": "564YLJHCgHsz"
      }
    }
  ]
}